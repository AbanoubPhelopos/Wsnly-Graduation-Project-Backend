import os
import sys

# --- STEP 1: FIX PATHS FIRST ---
# This must happen before importing any generated proto files
current_dir = os.path.dirname(os.path.abspath(__file__))
protos_path = os.path.join(current_dir, "protos")
sys.path.append(protos_path)

import grpc
from concurrent import futures
from transformers import pipeline
import logging
import re

# --- STEP 2: IMPORT PROTOS ---
# Now that 'protos' is in the path, these imports will work
import interpreter_pb2 as pb2
import interpreter_pb2_grpc as pb2_grpc

from geocoder import GoogleMapsGeocoder

# Configure Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# 1. Load the Model ONE TIME at startup
NER_MODEL_PATH = "./TransitModel"

print("ğŸš€ Loading AI Model... this may take a moment.")
nlp_pipeline = None
try:
    nlp_pipeline = pipeline(
        "token-classification",
        model=NER_MODEL_PATH,
        tokenizer=NER_MODEL_PATH,
        aggregation_strategy="simple",
    )
    print("âœ… Model Loaded!")
except Exception as error:
    logger.warning(f"Model load failed, using rule-based fallback extractor: {error}")


LOCATION_ALIASES = {
    "Ø§Ù„Ù Ù…Ø³ÙƒÙ†": "Ø£Ù„Ù Ù…Ø³ÙƒÙ†",
    "Ø§Ù„Ø§Ù„Ù Ù…Ø³ÙƒÙ†": "Ø£Ù„Ù Ù…Ø³ÙƒÙ†",
    "Ø¹Ø¨Ø§Ø³ÙŠÙ‡": "Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠØ©",
    "Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠÙ‡": "Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠØ©",
    "Ø³Ø±Ø§ÙŠØ§ Ø§Ù„Ù‚ÙŠÙ‡": "Ø³Ø±Ø§ÙŠØ§ Ø§Ù„Ù‚Ø¨Ø©",
    "Ø³Ø±Ø§ÙŠØ§ Ø§Ù„Ù‚Ø¨Ù‡": "Ø³Ø±Ø§ÙŠØ§ Ø§Ù„Ù‚Ø¨Ø©",
    "Ø§Ù„Ø³Ø±Ø§ÙŠØ§ Ø§Ù„Ù‚ÙŠÙ‡": "Ø³Ø±Ø§ÙŠØ§ Ø§Ù„Ù‚Ø¨Ø©",
    "Ø§Ù„Ø³Ø±Ø§ÙŠØ§ Ø§Ù„Ù‚Ø¨Ù‡": "Ø³Ø±Ø§ÙŠØ§ Ø§Ù„Ù‚Ø¨Ø©",
    "Ø´ÙŠØ±ØªÙˆÙ†": "Ø´ÙŠØ±Ø§ØªÙˆÙ†",
}

KNOWN_LOCATION_COORDINATES = {
    "Ø£Ù„Ù Ù…Ø³ÙƒÙ†": (30.1188972, 31.3400652),
    "Ø§Ù„Ù Ù…Ø³ÙƒÙ†": (30.1188972, 31.3400652),
    "Ø§Ù„Ø§Ù„Ù Ù…Ø³ÙƒÙ†": (30.1188972, 31.3400652),
    "Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠØ©": (30.0727858, 31.2840893),
    "Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠÙ‡": (30.0727858, 31.2840893),
    "Ù…ÙŠØ¯Ø§Ù† Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠØ©": (30.0650075, 31.2714452),
}


def _normalize_text(value: str) -> str:
    text = (value or "").strip()
    text = re.sub(r"\s+", " ", text)
    return text


def _clean_location_candidate(value: str) -> str:
    candidate = _normalize_text(value)
    candidate = re.sub(
        r"^(?:Ø§Ø±ÙƒØ¨\s+Ø§ÙŠÙ‡\s+Ø¹Ù„Ø´Ø§Ù†|Ø¹Ø§ÙŠØ²\s+Ø§Ø±ÙƒØ¨\s+Ø§ÙŠÙ‡\s+Ø¹Ù„Ø´Ø§Ù†|Ø¹Ø§ÙŠØ²|Ø¹Ø§ÙŠØ²Ø©|Ø¹Ø§ÙˆØ²Ù‡|Ø§Ø±ÙŠØ¯|Ù…Ø­ØªØ§Ø¬|Ø­Ø§Ø¨Ø¨|Ù„Ùˆ Ø³Ù…Ø­Øª|Ù…Ù…ÙƒÙ†|Ø§Ø±ÙˆØ­|Ø§Ø°Ù‡Ø¨|Ø±ÙˆØ­|Ø¹Ù„Ø´Ø§Ù†|Ø¹Ø´Ø§Ù†|Ø§Ø²Ø§ÙŠ|Ø§Ø²Ø§Ù‰|Ø§ÙˆØµÙ„|Ø§ÙˆØµÙ„)\s+",
        "",
        candidate,
        flags=re.IGNORECASE,
    )
    if " ÙÙŠ " in candidate:
        before_in, after_in = candidate.rsplit(" ÙÙŠ ", 1)
        if any(
            token in before_in
            for token in ("Ø¹Ù†Ø¯", "Ø¨ÙŠØª", "Ø´ØºÙ„", "Ù…ÙƒØ§Ù†", "Ù…Ù†Ø·Ù‚Ø©", "Ù†Ø§Ø­ÙŠØ©", "Ø¬Ù†Ø¨")
        ):
            candidate = after_in

    candidate = re.sub(r"^(?:Ø§Ø±ÙˆØ­|Ø§Ø°Ù‡Ø¨|Ø±ÙˆØ­)\s+", "", candidate, flags=re.IGNORECASE)
    candidate = re.sub(r"\s+(?:Ù„Ùˆ Ø³Ù…Ø­Øª|Ù…Ù† ÙØ¶Ù„Ùƒ)$", "", candidate, flags=re.IGNORECASE)
    return candidate.strip(" ,.-")


def _apply_alias(location_name: str) -> str:
    normalized = _normalize_text(location_name)
    return LOCATION_ALIASES.get(normalized, normalized)


def _resolve_known_coordinates(location_name: str):
    normalized = _normalize_text(location_name).replace("ØŒ", "")
    return KNOWN_LOCATION_COORDINATES.get(normalized)


def _extract_with_rules(text: str):
    normalized = _normalize_text(text)

    patterns = [
        re.compile(r"^Ù…Ù†\s+(?P<from>.+?)\s+(?:Ø§Ù„Ù‰|Ø¥Ù„Ù‰)\s+(?P<to>.+)$", re.IGNORECASE),
        re.compile(
            r"^(?:Ø¹Ø§ÙŠØ²|Ø¹Ø§ÙŠØ²Ø©|Ø¹Ø§ÙˆØ²Ù‡|Ø§Ø±ÙŠØ¯|Ù…Ø­ØªØ§Ø¬|Ø­Ø§Ø¨Ø¨)?\s*(?:Ø§Ø±ÙˆØ­|Ø§Ø°Ù‡Ø¨|Ø±ÙˆØ­)?\s*(?P<to>.+?)\s+Ù…Ù†\s+(?P<from>.+)$",
            re.IGNORECASE,
        ),
        re.compile(r"^from\s+(?P<from>.+?)\s+to\s+(?P<to>.+)$", re.IGNORECASE),
        re.compile(r"^to\s+(?P<to>.+?)\s+from\s+(?P<from>.+)$", re.IGNORECASE),
    ]

    for pattern in patterns:
        match = pattern.search(normalized)
        if not match:
            continue

        origin = _clean_location_candidate(match.group("from"))
        destination = _clean_location_candidate(match.group("to"))
        if origin and destination:
            return _apply_alias(origin), _apply_alias(destination)

    # Conversational pattern: destination first + explicit current location.
    convo = re.search(
        r"(?:Ø§Ø±ÙˆØ­|Ø§Ø°Ù‡Ø¨|Ø±ÙˆØ­)\s+(?:Ø§Ø²Ø§ÙŠ\s+|Ø§Ø²Ø§Ù‰\s+)?(?P<to>.+?)\s+(?:Ùˆ\s*Ø§Ù†Ø§|ÙˆØ§Ù†Ø§)\s+ÙÙŠ\s+(?P<from>.+)$",
        normalized,
        flags=re.IGNORECASE,
    )
    if convo:
        origin = _clean_location_candidate(convo.group("from"))
        destination = _clean_location_candidate(convo.group("to"))
        if origin and destination:
            return _apply_alias(origin), _apply_alias(destination)

    # Destination-only request. Source can be supplied by API current_location.
    destination_only = re.search(
        r"(?:Ø¹Ø§ÙŠØ²|Ø¹Ø§ÙŠØ²Ø©|Ø¹Ø§ÙˆØ²Ù‡|Ø§Ø±ÙŠØ¯|Ù…Ø­ØªØ§Ø¬|Ø­Ø§Ø¨Ø¨)?\s*(?:Ø§Ø±ÙˆØ­|Ø§Ø°Ù‡Ø¨|Ø±ÙˆØ­)\s+(?P<to>.+)$",
        normalized,
        flags=re.IGNORECASE,
    )
    if destination_only:
        destination = _clean_location_candidate(destination_only.group("to"))
        destination = re.sub(r"\s+(?:Ùˆ\s*Ø§Ù†Ø§.*)$", "", destination, flags=re.IGNORECASE)
        if destination:
            return "", _apply_alias(destination)

    if " Ù…Ù† " in normalized:
        before_from, after_from = normalized.rsplit(" Ù…Ù† ", 1)
        origin = _clean_location_candidate(after_from)
        destination = ""

        if " Ø§Ù„Ù‰ " in before_from:
            destination = _clean_location_candidate(before_from.split(" Ø§Ù„Ù‰ ")[-1])
        elif " Ø¥Ù„Ù‰ " in before_from:
            destination = _clean_location_candidate(before_from.split(" Ø¥Ù„Ù‰ ")[-1])
        else:
            tokens = before_from.strip().split()
            destination = _clean_location_candidate(tokens[-1] if tokens else "")

        if origin and destination:
            return _apply_alias(origin), _apply_alias(destination)

    return "", ""


def extract_locations(text):
    if nlp_pipeline is not None:
        results = nlp_pipeline(text)
        from_loc_name = ""
        to_loc_name = ""

        for entity in results:
            label = (entity.get("entity_group") or entity.get("entity") or "").upper()
            word = _clean_location_candidate(entity.get("word", "").replace("##", ""))

            if not word:
                continue

            if "FROM" in label:
                from_loc_name = word
            elif "TO" in label:
                to_loc_name = word

        if from_loc_name and to_loc_name:
            return _apply_alias(from_loc_name), _apply_alias(to_loc_name)

    return _extract_with_rules(text)


# Initialize Services
geocoder = GoogleMapsGeocoder()


class TransitInterpreterService(pb2_grpc.TransitInterpreterServicer):
    def ExtractRoute(self, request, context):
        text = (request.text or "").strip()
        if not text:
            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
            context.set_details("text is required")
            return pb2.RouteResponse()

        logger.info(f"ğŸ“© Received request: {text}")

        from_loc_name, to_loc_name = extract_locations(text)

        if not to_loc_name:
            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
            context.set_details("could not extract destination from text")
            return pb2.RouteResponse(intent="unknown")

        logger.info(f"ğŸ“ Extracted: From '{from_loc_name}' To '{to_loc_name}'")

        # 3. Geocode
        from_coords = None
        if from_loc_name:
            from_coords = _resolve_known_coordinates(
                from_loc_name
            ) or geocoder.get_coordinates(from_loc_name)
        to_coords = _resolve_known_coordinates(to_loc_name) or geocoder.get_coordinates(
            to_loc_name
        )

        if not to_coords:
            logger.warning("âŒ Geocoding failed for one or more locations.")
            context.set_code(grpc.StatusCode.NOT_FOUND)
            context.set_details("could not geocode destination location")
            return pb2.RouteResponse(
                from_location=from_loc_name,
                to_location=to_loc_name,
                intent="unknown",
            )

        logger.info(f"ğŸŒ Coordinates: {from_coords} -> {to_coords}")

        response = pb2.RouteResponse(
            from_location=from_loc_name,
            to_location=to_loc_name,
            intent="standard",
        )
        if from_coords:
            response.from_coordinates.CopyFrom(
                pb2.Location(latitude=from_coords[0], longitude=from_coords[1])
            )
        response.to_coordinates.CopyFrom(
            pb2.Location(latitude=to_coords[0], longitude=to_coords[1])
        )
        return response


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    pb2_grpc.add_TransitInterpreterServicer_to_server(
        TransitInterpreterService(), server
    )
    server.add_insecure_port("[::]:50052")
    print("ğŸŒ AI Interpreter Service running on port 50052...")
    server.start()
    server.wait_for_termination()


if __name__ == "__main__":
    serve()
